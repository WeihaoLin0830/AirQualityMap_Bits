{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the databe of CALIOPE\n",
    "\n",
    "```markdown\n",
    "The data is from CALIOPE, a model that predicted the concentrations we have in the data. We will use this data to train our model, which will help increase the resolution by first predicting the 4 stations that are not provided within the database.\n",
    "When we faced the problem, the biggest issue was the volume of the dataframe. Given the hardware circumstances of our local PC, it was inevitable to split the data, although we are aware that this will result in some loss of information.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "The code reads multiple NetCDF files from the directory provided for us, extracts 1000 random rows from each file, concatenates the extracted data into a single DataFrame, and saves it as a CSV file. A big problem with this method of extraction of datas is that some of the points will be missed in our dataset of train, which will cause a great bias in the future model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def extract_random_rows_v3(nc_data, num_rows=1000):\n",
    "    \"\"\" Extraer 1000 filas aleatorias de las columnas time, lat, lon y sconcno2. \"\"\"\n",
    "    # Convertir el dataset de xarray a DataFrame y seleccionar solo las columnas necesarias\n",
    "    df = nc_data[['time', 'lat', 'lon', 'sconcno2']].to_dataframe().reset_index()\n",
    "\n",
    "    # Seleccionar 1000 filas aleatorias\n",
    "    if len(df) > num_rows:\n",
    "        sampled_df = df.sample(n=num_rows, random_state=42).reset_index(drop=True)\n",
    "    else:\n",
    "        sampled_df = df\n",
    "\n",
    "    return sampled_df\n",
    "\n",
    "\n",
    "# Ruta de la carpeta donde se encuentran los archivos .nc\n",
    "directorio = r'C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/'\n",
    "\n",
    "# Listar los archivos .nc de la carpeta\n",
    "archivos = [archivo for archivo in os.listdir(directorio) if archivo.endswith('.nc')]\n",
    "\n",
    "# Lista para almacenar todos los DataFrames generados\n",
    "lista_dataframes = []\n",
    "\n",
    "# Recorre todos los archivos .nc de la carpeta\n",
    "for archivo in archivos:\n",
    "    try:\n",
    "        ruta_archivo = os.path.join(directorio, archivo)\n",
    "        print(f\"Procesando archivo: {archivo}\")\n",
    "        \n",
    "        # Abrir el archivo NetCDF\n",
    "        nc_data = xr.open_dataset(ruta_archivo)\n",
    "        \n",
    "        # Extraer 1000 filas aleatorias\n",
    "        sampled_data = extract_random_rows_v3(nc_data)\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        lista_dataframes.append(sampled_data)\n",
    "        \n",
    "        # Cerrar el dataset para liberar memoria\n",
    "        nc_data.close()\n",
    "        \n",
    "        print(f\"Archivo procesado correctamente: {archivo} | Filas extraídas: {sampled_data.shape[0]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {archivo}: {e}\")\n",
    "\n",
    "# Concatenar todos los DataFrames\n",
    "data_final = pd.concat(lista_dataframes, ignore_index=True)\n",
    "data_final = data_final.drop(columns=['x', 'y', 'lev'])\n",
    "# Guardar el DataFrame final como CSV\n",
    "output_path = 'C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/NO2_final.csv'\n",
    "data_final.to_csv(output_path, index=False)\n",
    "print(f\"Archivo CSV guardado en: {output_path}\")\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(\"Vista previa de los primeros registros:\")\n",
    "print(data_final.head())\n",
    "\n",
    "# Mostrar información general del DataFrame\n",
    "print(f\"Total de filas: {data_final.shape[0]}\")\n",
    "print(f\"Columnas del DataFrame: {data_final.columns}\")\n",
    "\n",
    "# Mostrar una vista previa de los primeros 5 registros de cada conjunto\n",
    "\"\"\" import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Sampled Data from File 1 (Final V2)\", dataframe=sampled_data_1_final_v2.head())\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time        datetime64[ns]\n",
      "lat                float64\n",
      "lon                float64\n",
      "sconcno2           float64\n",
      "dtype: object\n",
      "                                time            lat            lon  \\\n",
      "count                         332000  332000.000000  332000.000000   \n",
      "mean   2023-07-02 15:15:34.048192512      41.638951       1.717181   \n",
      "min              2023-01-01 00:00:00      40.276993       0.033142   \n",
      "25%              2023-04-03 12:00:00      40.939259       0.903862   \n",
      "50%              2023-06-29 12:00:00      41.665867       1.703217   \n",
      "75%              2023-10-02 12:00:00      42.317552       2.527702   \n",
      "max              2024-01-01 23:00:00      43.028343       3.469818   \n",
      "std                              NaN       0.779556       0.948098   \n",
      "\n",
      "           sconcno2  \n",
      "count  3.320000e+05  \n",
      "mean   8.617962e+33  \n",
      "min    8.777442e-06  \n",
      "25%    3.175537e-04  \n",
      "50%    6.749267e-04  \n",
      "75%    1.526916e-03  \n",
      "max    9.969210e+36  \n",
      "std    2.929851e+35  \n",
      "time\n",
      "2023-12-31 18:00:00    55\n",
      "2023-01-02 18:00:00    55\n",
      "2023-04-29 18:00:00    55\n",
      "2023-07-02 18:00:00    55\n",
      "2023-09-09 18:00:00    55\n",
      "                       ..\n",
      "2023-06-01 14:00:00    11\n",
      "2023-01-24 14:00:00    11\n",
      "2023-07-30 14:00:00    11\n",
      "2023-08-01 14:00:00    11\n",
      "2023-03-24 14:00:00    11\n",
      "Name: count, Length: 8544, dtype: int64\n",
      "lat\n",
      "42.715496    664\n",
      "42.876064    664\n",
      "42.729930    664\n",
      "41.045160    664\n",
      "42.859695    664\n",
      "            ... \n",
      "41.213387    332\n",
      "41.497707    332\n",
      "42.069430    332\n",
      "42.341263    332\n",
      "40.509525    332\n",
      "Name: count, Length: 991, dtype: int64\n",
      "lon\n",
      "0.363892    664\n",
      "1.047058    664\n",
      "2.719025    664\n",
      "2.455536    664\n",
      "3.296356    664\n",
      "           ... \n",
      "0.144745    332\n",
      "0.603271    332\n",
      "0.464539    332\n",
      "3.137085    332\n",
      "1.492310    332\n",
      "Name: count, Length: 988, dtype: int64\n",
      "sconcno2\n",
      "9.969210e+36    287\n",
      "7.967388e-04      3\n",
      "7.922540e-04      3\n",
      "3.276085e-04      3\n",
      "1.243901e-03      3\n",
      "               ... \n",
      "1.138341e-03      1\n",
      "9.846125e-04      1\n",
      "6.639797e-04      1\n",
      "1.614824e-03      1\n",
      "6.554534e-04      1\n",
      "Name: count, Length: 330349, dtype: int64\n",
      "Filas con sconcno2 = 9.969210e+36:\n",
      "                      time        lat       lon      sconcno2\n",
      "210002 2023-08-21 13:00:00  40.509525  1.546783  9.969210e+36\n",
      "210008 2023-08-21 15:00:00  41.759100  1.644409  9.969210e+36\n",
      "210013 2023-08-21 12:00:00  41.021355  1.115356  9.969210e+36\n",
      "210018 2023-08-21 15:00:00  41.534832  2.845764  9.969210e+36\n",
      "210019 2023-08-21 21:00:00  42.136223  3.264008  9.969210e+36\n",
      "...                    ...        ...       ...           ...\n",
      "210986 2023-08-21 17:00:00  42.567600  0.674255  9.969210e+36\n",
      "210987 2023-08-20 23:00:00  40.396004  1.681274  9.969210e+36\n",
      "210991 2023-08-20 23:00:00  42.959700  0.179749  9.969210e+36\n",
      "210993 2023-08-21 18:00:00  40.660126  1.616364  9.969210e+36\n",
      "210996 2023-08-21 14:00:00  41.497707  0.603271  9.969210e+36\n",
      "\n",
      "[287 rows x 4 columns]\n",
      "DataFrame después de eliminar las filas con fechas 20 y 21 de agosto:\n",
      "                      time        lat       lon  sconcno2\n",
      "0      2023-01-01 10:00:00  42.534092  3.069458  0.002094\n",
      "1      2023-01-02 01:00:00  42.443565  0.606293  0.000655\n",
      "2      2023-01-02 13:00:00  40.509525  1.546783  0.002464\n",
      "3      2023-01-01 03:00:00  41.306800  0.353058  0.001805\n",
      "4      2023-01-01 19:00:00  41.271725  2.498596  0.003971\n",
      "...                    ...        ...       ...       ...\n",
      "331995 2024-01-01 03:00:00  41.213387  0.144745  0.001138\n",
      "331996 2024-01-01 14:00:00  41.497707  0.603271  0.000985\n",
      "331997 2023-12-31 18:00:00  42.069430  0.464539  0.000664\n",
      "331998 2024-01-01 11:00:00  42.341263  3.137085  0.001615\n",
      "331999 2024-01-01 08:00:00  42.368774  1.492310  0.000617\n",
      "\n",
      "[330498 rows x 4 columns]\n",
      "time\n",
      "2023-08-10 18:00:00    55\n",
      "2023-12-31 18:00:00    55\n",
      "2023-01-02 18:00:00    55\n",
      "2023-08-12 18:00:00    55\n",
      "2023-12-14 18:00:00    55\n",
      "                       ..\n",
      "2023-07-10 14:00:00    11\n",
      "2023-03-11 14:00:00    11\n",
      "2023-11-22 14:00:00    11\n",
      "2023-11-29 14:00:00    11\n",
      "2023-10-26 14:00:00    11\n",
      "Name: count, Length: 8496, dtype: int64\n",
      "lat\n",
      "41.045160    662\n",
      "42.876064    662\n",
      "42.491850    661\n",
      "41.284397    661\n",
      "42.729930    661\n",
      "            ... \n",
      "40.838060    330\n",
      "41.367958    330\n",
      "40.897537    330\n",
      "41.053530    330\n",
      "41.718697    330\n",
      "Name: count, Length: 991, dtype: int64\n",
      "lon\n",
      "0.363892    662\n",
      "2.719025    662\n",
      "1.563446    661\n",
      "0.169312    661\n",
      "1.047058    661\n",
      "           ... \n",
      "1.060516    330\n",
      "0.674255    330\n",
      "1.152802    330\n",
      "1.005890    330\n",
      "2.893768    330\n",
      "Name: count, Length: 988, dtype: int64\n",
      "sconcno2\n",
      "0.000328    3\n",
      "0.001244    3\n",
      "0.000792    3\n",
      "0.000797    3\n",
      "0.000442    2\n",
      "           ..\n",
      "0.001138    1\n",
      "0.000985    1\n",
      "0.000664    1\n",
      "0.001615    1\n",
      "0.000617    1\n",
      "Name: count, Length: 329139, dtype: int64\n",
      "                                time            lat            lon  \\\n",
      "count                         330498  330498.000000  330498.000000   \n",
      "mean   2023-07-02 09:53:43.974729216      41.638937       1.717174   \n",
      "min              2023-01-01 00:00:00      40.276993       0.033142   \n",
      "25%              2023-04-03 02:00:00      40.938084       0.904480   \n",
      "50%              2023-06-28 18:00:00      41.668278       1.704041   \n",
      "75%              2023-10-02 21:00:00      42.316174       2.525574   \n",
      "max              2024-01-01 23:00:00      43.028343       3.469818   \n",
      "std                              NaN       0.779539       0.948091   \n",
      "\n",
      "            sconcno2  \n",
      "count  330498.000000  \n",
      "mean        0.001483  \n",
      "min         0.000009  \n",
      "25%         0.000318  \n",
      "50%         0.000675  \n",
      "75%         0.001525  \n",
      "max         0.060920  \n",
      "std         0.002671  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "NO2 = pd.read_csv('C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/NO2_final.csv')\n",
    "NO2['time'] = pd.to_datetime(NO2['time'])\n",
    "print(NO2.dtypes)\n",
    "\n",
    "print(NO2.describe())\n",
    "for i in NO2.columns:\n",
    "    print(NO2[i].value_counts())\n",
    "\n",
    "filas_con_valor = NO2.loc[NO2['sconcno2'] == 9.969210e+36]\n",
    "\n",
    "print(\"Filas con sconcno2 = 9.969210e+36:\")\n",
    "print(filas_con_valor)\n",
    "\n",
    "df_filtrado = NO2.loc[~NO2['time'].dt.strftime('%Y-%m-%d').isin(['2023-08-20', '2023-08-21'])]\n",
    "\n",
    "print(\"DataFrame después de eliminar las filas con fechas 20 y 21 de agosto:\")\n",
    "print(df_filtrado)\n",
    "for i in df_filtrado.columns:\n",
    "    print(df_filtrado[i].value_counts())\n",
    "print(df_filtrado.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivo: sconcno2_2023010100.nc\n",
      "Procesando archivo: sconcno2_2023010200.nc\n",
      "Procesando archivo: sconcno2_2023010300.nc\n",
      "Procesando archivo: sconcno2_2023010400.nc\n",
      "Procesando archivo: sconcno2_2023010500.nc\n",
      "Procesando archivo: sconcno2_2023010600.nc\n",
      "Procesando archivo: sconcno2_2023010700.nc\n",
      "Procesando archivo: sconcno2_2023010800.nc\n",
      "Procesando archivo: sconcno2_2023010900.nc\n",
      "Procesando archivo: sconcno2_2023011000.nc\n",
      "Procesando archivo: sconcno2_2023011100.nc\n",
      "Procesando archivo: sconcno2_2023011200.nc\n",
      "Procesando archivo: sconcno2_2023011400.nc\n",
      "Procesando archivo: sconcno2_2023011500.nc\n",
      "Procesando archivo: sconcno2_2023011600.nc\n",
      "Procesando archivo: sconcno2_2023011700.nc\n",
      "Procesando archivo: sconcno2_2023011800.nc\n",
      "Procesando archivo: sconcno2_2023011900.nc\n",
      "Procesando archivo: sconcno2_2023012000.nc\n",
      "Procesando archivo: sconcno2_2023012200.nc\n",
      "Procesando archivo: sconcno2_2023012300.nc\n",
      "Procesando archivo: sconcno2_2023012500.nc\n",
      "Procesando archivo: sconcno2_2023012600.nc\n",
      "Procesando archivo: sconcno2_2023012700.nc\n",
      "Procesando archivo: sconcno2_2023012800.nc\n",
      "Procesando archivo: sconcno2_2023012900.nc\n",
      "Procesando archivo: sconcno2_2023013000.nc\n",
      "Procesando archivo: sconcno2_2023013100.nc\n",
      "Procesando archivo: sconcno2_2023020100.nc\n",
      "Procesando archivo: sconcno2_2023020200.nc\n",
      "Procesando archivo: sconcno2_2023020300.nc\n",
      "Procesando archivo: sconcno2_2023020400.nc\n",
      "Procesando archivo: sconcno2_2023020500.nc\n",
      "Procesando archivo: sconcno2_2023020600.nc\n",
      "Procesando archivo: sconcno2_2023020700.nc\n",
      "Procesando archivo: sconcno2_2023020800.nc\n",
      "Procesando archivo: sconcno2_2023020900.nc\n",
      "Procesando archivo: sconcno2_2023021000.nc\n",
      "Procesando archivo: sconcno2_2023021100.nc\n",
      "Procesando archivo: sconcno2_2023021200.nc\n",
      "Procesando archivo: sconcno2_2023021300.nc\n",
      "Procesando archivo: sconcno2_2023021400.nc\n",
      "Procesando archivo: sconcno2_2023021500.nc\n",
      "Procesando archivo: sconcno2_2023021600.nc\n",
      "Procesando archivo: sconcno2_2023021700.nc\n",
      "Procesando archivo: sconcno2_2023021800.nc\n",
      "Procesando archivo: sconcno2_2023021900.nc\n",
      "Procesando archivo: sconcno2_2023022000.nc\n",
      "Procesando archivo: sconcno2_2023022100.nc\n",
      "Procesando archivo: sconcno2_2023022200.nc\n",
      "Procesando archivo: sconcno2_2023022300.nc\n",
      "Procesando archivo: sconcno2_2023022400.nc\n",
      "Procesando archivo: sconcno2_2023022500.nc\n",
      "Procesando archivo: sconcno2_2023022600.nc\n",
      "Procesando archivo: sconcno2_2023022700.nc\n",
      "Procesando archivo: sconcno2_2023022800.nc\n",
      "Procesando archivo: sconcno2_2023030100.nc\n",
      "Procesando archivo: sconcno2_2023030200.nc\n",
      "Procesando archivo: sconcno2_2023030300.nc\n",
      "Procesando archivo: sconcno2_2023030400.nc\n",
      "Procesando archivo: sconcno2_2023030500.nc\n",
      "Procesando archivo: sconcno2_2023030600.nc\n",
      "Procesando archivo: sconcno2_2023030700.nc\n",
      "Procesando archivo: sconcno2_2023030800.nc\n",
      "Procesando archivo: sconcno2_2023030900.nc\n",
      "Procesando archivo: sconcno2_2023031000.nc\n",
      "Procesando archivo: sconcno2_2023031500.nc\n",
      "Procesando archivo: sconcno2_2023031600.nc\n",
      "Procesando archivo: sconcno2_2023031800.nc\n",
      "Procesando archivo: sconcno2_2023031900.nc\n",
      "Procesando archivo: sconcno2_2023032000.nc\n",
      "Procesando archivo: sconcno2_2023032100.nc\n",
      "Procesando archivo: sconcno2_2023032200.nc\n",
      "Procesando archivo: sconcno2_2023032300.nc\n",
      "Procesando archivo: sconcno2_2023032500.nc\n",
      "Procesando archivo: sconcno2_2023032600.nc\n",
      "Procesando archivo: sconcno2_2023032700.nc\n",
      "Procesando archivo: sconcno2_2023032800.nc\n",
      "Procesando archivo: sconcno2_2023032900.nc\n",
      "Procesando archivo: sconcno2_2023033000.nc\n",
      "Procesando archivo: sconcno2_2023033100.nc\n",
      "Procesando archivo: sconcno2_2023040100.nc\n",
      "Procesando archivo: sconcno2_2023040200.nc\n",
      "Procesando archivo: sconcno2_2023040300.nc\n",
      "Procesando archivo: sconcno2_2023040400.nc\n",
      "Procesando archivo: sconcno2_2023040500.nc\n",
      "Procesando archivo: sconcno2_2023040600.nc\n",
      "Procesando archivo: sconcno2_2023040700.nc\n",
      "Procesando archivo: sconcno2_2023040800.nc\n",
      "Procesando archivo: sconcno2_2023040900.nc\n",
      "Procesando archivo: sconcno2_2023041000.nc\n",
      "Procesando archivo: sconcno2_2023041100.nc\n",
      "Procesando archivo: sconcno2_2023041200.nc\n",
      "Procesando archivo: sconcno2_2023041300.nc\n",
      "Procesando archivo: sconcno2_2023041400.nc\n",
      "Procesando archivo: sconcno2_2023041500.nc\n",
      "Procesando archivo: sconcno2_2023041600.nc\n",
      "Procesando archivo: sconcno2_2023041700.nc\n",
      "Procesando archivo: sconcno2_2023041800.nc\n",
      "Procesando archivo: sconcno2_2023041900.nc\n",
      "Procesando archivo: sconcno2_2023042000.nc\n",
      "Procesando archivo: sconcno2_2023042200.nc\n",
      "Procesando archivo: sconcno2_2023042300.nc\n",
      "Procesando archivo: sconcno2_2023042400.nc\n",
      "Procesando archivo: sconcno2_2023042500.nc\n",
      "Procesando archivo: sconcno2_2023042600.nc\n",
      "Procesando archivo: sconcno2_2023042700.nc\n",
      "Procesando archivo: sconcno2_2023042800.nc\n",
      "Procesando archivo: sconcno2_2023042900.nc\n",
      "Procesando archivo: sconcno2_2023043000.nc\n",
      "Procesando archivo: sconcno2_2023050100.nc\n",
      "Procesando archivo: sconcno2_2023050200.nc\n",
      "Procesando archivo: sconcno2_2023050300.nc\n",
      "Procesando archivo: sconcno2_2023050400.nc\n",
      "Procesando archivo: sconcno2_2023050500.nc\n",
      "Procesando archivo: sconcno2_2023050600.nc\n",
      "Procesando archivo: sconcno2_2023050700.nc\n",
      "Procesando archivo: sconcno2_2023050800.nc\n",
      "Procesando archivo: sconcno2_2023050900.nc\n",
      "Procesando archivo: sconcno2_2023051000.nc\n",
      "Procesando archivo: sconcno2_2023051100.nc\n",
      "Procesando archivo: sconcno2_2023051200.nc\n",
      "Procesando archivo: sconcno2_2023051300.nc\n",
      "Procesando archivo: sconcno2_2023051400.nc\n",
      "Procesando archivo: sconcno2_2023051500.nc\n",
      "Procesando archivo: sconcno2_2023051600.nc\n",
      "Procesando archivo: sconcno2_2023051800.nc\n",
      "Procesando archivo: sconcno2_2023051900.nc\n",
      "Procesando archivo: sconcno2_2023052000.nc\n",
      "Procesando archivo: sconcno2_2023052100.nc\n",
      "Procesando archivo: sconcno2_2023052200.nc\n",
      "Procesando archivo: sconcno2_2023052300.nc\n",
      "Procesando archivo: sconcno2_2023052400.nc\n",
      "Procesando archivo: sconcno2_2023052500.nc\n",
      "Procesando archivo: sconcno2_2023052600.nc\n",
      "Procesando archivo: sconcno2_2023052700.nc\n",
      "Procesando archivo: sconcno2_2023052800.nc\n",
      "Procesando archivo: sconcno2_2023052900.nc\n",
      "Procesando archivo: sconcno2_2023053000.nc\n",
      "Procesando archivo: sconcno2_2023053100.nc\n",
      "Procesando archivo: sconcno2_2023060300.nc\n",
      "Procesando archivo: sconcno2_2023060400.nc\n",
      "Procesando archivo: sconcno2_2023060500.nc\n",
      "Procesando archivo: sconcno2_2023060600.nc\n",
      "Procesando archivo: sconcno2_2023060700.nc\n",
      "Procesando archivo: sconcno2_2023060800.nc\n",
      "Procesando archivo: sconcno2_2023060900.nc\n",
      "Procesando archivo: sconcno2_2023061000.nc\n",
      "Procesando archivo: sconcno2_2023061100.nc\n",
      "Procesando archivo: sconcno2_2023061200.nc\n",
      "Procesando archivo: sconcno2_2023061300.nc\n",
      "Procesando archivo: sconcno2_2023061400.nc\n",
      "Procesando archivo: sconcno2_2023061500.nc\n",
      "Procesando archivo: sconcno2_2023061600.nc\n",
      "Procesando archivo: sconcno2_2023061700.nc\n",
      "Procesando archivo: sconcno2_2023061800.nc\n",
      "Procesando archivo: sconcno2_2023061900.nc\n",
      "Procesando archivo: sconcno2_2023062000.nc\n",
      "Procesando archivo: sconcno2_2023062100.nc\n",
      "Procesando archivo: sconcno2_2023062200.nc\n",
      "Procesando archivo: sconcno2_2023062300.nc\n",
      "Procesando archivo: sconcno2_2023062400.nc\n",
      "Procesando archivo: sconcno2_2023062500.nc\n",
      "Procesando archivo: sconcno2_2023062600.nc\n",
      "Procesando archivo: sconcno2_2023062700.nc\n",
      "Procesando archivo: sconcno2_2023062800.nc\n",
      "Procesando archivo: sconcno2_2023062900.nc\n",
      "Procesando archivo: sconcno2_2023063000.nc\n",
      "Procesando archivo: sconcno2_2023070100.nc\n",
      "Procesando archivo: sconcno2_2023070200.nc\n",
      "Procesando archivo: sconcno2_2023070300.nc\n",
      "Procesando archivo: sconcno2_2023070400.nc\n",
      "Procesando archivo: sconcno2_2023070500.nc\n",
      "Procesando archivo: sconcno2_2023070600.nc\n",
      "Procesando archivo: sconcno2_2023070700.nc\n",
      "Procesando archivo: sconcno2_2023070800.nc\n",
      "Procesando archivo: sconcno2_2023070900.nc\n",
      "Procesando archivo: sconcno2_2023071100.nc\n",
      "Procesando archivo: sconcno2_2023071200.nc\n",
      "Procesando archivo: sconcno2_2023071300.nc\n",
      "Procesando archivo: sconcno2_2023071500.nc\n",
      "Procesando archivo: sconcno2_2023071600.nc\n",
      "Procesando archivo: sconcno2_2023071800.nc\n",
      "Procesando archivo: sconcno2_2023071900.nc\n",
      "Procesando archivo: sconcno2_2023072000.nc\n",
      "Procesando archivo: sconcno2_2023072100.nc\n",
      "Procesando archivo: sconcno2_2023072200.nc\n",
      "Procesando archivo: sconcno2_2023072300.nc\n",
      "Procesando archivo: sconcno2_2023072400.nc\n",
      "Procesando archivo: sconcno2_2023072500.nc\n",
      "Procesando archivo: sconcno2_2023072600.nc\n",
      "Procesando archivo: sconcno2_2023072700.nc\n",
      "Procesando archivo: sconcno2_2023072900.nc\n",
      "Procesando archivo: sconcno2_2023073100.nc\n",
      "Procesando archivo: sconcno2_2023080400.nc\n",
      "Procesando archivo: sconcno2_2023080500.nc\n",
      "Procesando archivo: sconcno2_2023080600.nc\n",
      "Procesando archivo: sconcno2_2023080700.nc\n",
      "Procesando archivo: sconcno2_2023080800.nc\n",
      "Procesando archivo: sconcno2_2023080900.nc\n",
      "Procesando archivo: sconcno2_2023081000.nc\n",
      "Procesando archivo: sconcno2_2023081100.nc\n",
      "Procesando archivo: sconcno2_2023081200.nc\n",
      "Procesando archivo: sconcno2_2023081300.nc\n",
      "Procesando archivo: sconcno2_2023081400.nc\n",
      "Procesando archivo: sconcno2_2023081500.nc\n",
      "Procesando archivo: sconcno2_2023081600.nc\n",
      "Procesando archivo: sconcno2_2023081700.nc\n",
      "Procesando archivo: sconcno2_2023081800.nc\n",
      "Procesando archivo: sconcno2_2023081900.nc\n",
      "Procesando archivo: sconcno2_2023082000.nc\n",
      "Procesando archivo: sconcno2_2023082400.nc\n",
      "Procesando archivo: sconcno2_2023082500.nc\n",
      "Procesando archivo: sconcno2_2023082600.nc\n",
      "Procesando archivo: sconcno2_2023082700.nc\n",
      "Procesando archivo: sconcno2_2023082800.nc\n",
      "Procesando archivo: sconcno2_2023082900.nc\n",
      "Procesando archivo: sconcno2_2023083000.nc\n",
      "Procesando archivo: sconcno2_2023083100.nc\n",
      "Procesando archivo: sconcno2_2023090100.nc\n",
      "Procesando archivo: sconcno2_2023090200.nc\n",
      "Procesando archivo: sconcno2_2023090300.nc\n",
      "Procesando archivo: sconcno2_2023090400.nc\n",
      "Procesando archivo: sconcno2_2023090500.nc\n",
      "Procesando archivo: sconcno2_2023090600.nc\n",
      "Procesando archivo: sconcno2_2023090700.nc\n",
      "Procesando archivo: sconcno2_2023090800.nc\n",
      "Procesando archivo: sconcno2_2023090900.nc\n",
      "Procesando archivo: sconcno2_2023091000.nc\n",
      "Procesando archivo: sconcno2_2023091100.nc\n",
      "Procesando archivo: sconcno2_2023091200.nc\n",
      "Procesando archivo: sconcno2_2023091300.nc\n",
      "Procesando archivo: sconcno2_2023091400.nc\n",
      "Procesando archivo: sconcno2_2023091500.nc\n",
      "Procesando archivo: sconcno2_2023091600.nc\n",
      "Procesando archivo: sconcno2_2023091700.nc\n",
      "Procesando archivo: sconcno2_2023091800.nc\n",
      "Procesando archivo: sconcno2_2023091900.nc\n",
      "Procesando archivo: sconcno2_2023092000.nc\n",
      "Procesando archivo: sconcno2_2023092100.nc\n",
      "Procesando archivo: sconcno2_2023092200.nc\n",
      "Procesando archivo: sconcno2_2023092300.nc\n",
      "Procesando archivo: sconcno2_2023092400.nc\n",
      "Procesando archivo: sconcno2_2023092500.nc\n",
      "Procesando archivo: sconcno2_2023092600.nc\n",
      "Procesando archivo: sconcno2_2023092700.nc\n",
      "Procesando archivo: sconcno2_2023092800.nc\n",
      "Procesando archivo: sconcno2_2023092900.nc\n",
      "Procesando archivo: sconcno2_2023100100.nc\n",
      "Procesando archivo: sconcno2_2023100200.nc\n",
      "Procesando archivo: sconcno2_2023100300.nc\n",
      "Procesando archivo: sconcno2_2023100400.nc\n",
      "Procesando archivo: sconcno2_2023100500.nc\n",
      "Procesando archivo: sconcno2_2023100600.nc\n",
      "Procesando archivo: sconcno2_2023100700.nc\n",
      "Procesando archivo: sconcno2_2023100800.nc\n",
      "Procesando archivo: sconcno2_2023100900.nc\n",
      "Procesando archivo: sconcno2_2023101100.nc\n",
      "Procesando archivo: sconcno2_2023101200.nc\n",
      "Procesando archivo: sconcno2_2023101400.nc\n",
      "Procesando archivo: sconcno2_2023101500.nc\n",
      "Procesando archivo: sconcno2_2023101600.nc\n",
      "Procesando archivo: sconcno2_2023101700.nc\n",
      "Procesando archivo: sconcno2_2023101800.nc\n",
      "Procesando archivo: sconcno2_2023101900.nc\n",
      "Procesando archivo: sconcno2_2023102000.nc\n",
      "Procesando archivo: sconcno2_2023102100.nc\n",
      "Procesando archivo: sconcno2_2023102200.nc\n",
      "Procesando archivo: sconcno2_2023102300.nc\n",
      "Procesando archivo: sconcno2_2023102400.nc\n",
      "Procesando archivo: sconcno2_2023102500.nc\n",
      "Procesando archivo: sconcno2_2023102700.nc\n",
      "Procesando archivo: sconcno2_2023102800.nc\n",
      "Procesando archivo: sconcno2_2023102900.nc\n",
      "Procesando archivo: sconcno2_2023103000.nc\n",
      "Procesando archivo: sconcno2_2023103100.nc\n",
      "Procesando archivo: sconcno2_2023110100.nc\n",
      "Procesando archivo: sconcno2_2023110200.nc\n",
      "Procesando archivo: sconcno2_2023110300.nc\n",
      "Procesando archivo: sconcno2_2023110400.nc\n",
      "Procesando archivo: sconcno2_2023110500.nc\n",
      "Procesando archivo: sconcno2_2023110600.nc\n",
      "Procesando archivo: sconcno2_2023110700.nc\n",
      "Procesando archivo: sconcno2_2023110800.nc\n",
      "Procesando archivo: sconcno2_2023110900.nc\n",
      "Procesando archivo: sconcno2_2023111000.nc\n",
      "Procesando archivo: sconcno2_2023111100.nc\n",
      "Procesando archivo: sconcno2_2023111500.nc\n",
      "Procesando archivo: sconcno2_2023111600.nc\n",
      "Procesando archivo: sconcno2_2023111700.nc\n",
      "Procesando archivo: sconcno2_2023111800.nc\n",
      "Procesando archivo: sconcno2_2023111900.nc\n",
      "Procesando archivo: sconcno2_2023112000.nc\n",
      "Procesando archivo: sconcno2_2023112100.nc\n",
      "Procesando archivo: sconcno2_2023112300.nc\n",
      "Procesando archivo: sconcno2_2023112400.nc\n",
      "Procesando archivo: sconcno2_2023112500.nc\n",
      "Procesando archivo: sconcno2_2023112600.nc\n",
      "Procesando archivo: sconcno2_2023112700.nc\n",
      "Procesando archivo: sconcno2_2023112800.nc\n",
      "Procesando archivo: sconcno2_2023113000.nc\n",
      "Procesando archivo: sconcno2_2023120100.nc\n",
      "Procesando archivo: sconcno2_2023120200.nc\n",
      "Procesando archivo: sconcno2_2023120300.nc\n",
      "Procesando archivo: sconcno2_2023120400.nc\n",
      "Procesando archivo: sconcno2_2023120500.nc\n",
      "Procesando archivo: sconcno2_2023120600.nc\n",
      "Procesando archivo: sconcno2_2023120700.nc\n",
      "Procesando archivo: sconcno2_2023120800.nc\n",
      "Procesando archivo: sconcno2_2023120900.nc\n",
      "Procesando archivo: sconcno2_2023121000.nc\n",
      "Procesando archivo: sconcno2_2023121100.nc\n",
      "Procesando archivo: sconcno2_2023121200.nc\n",
      "Procesando archivo: sconcno2_2023121300.nc\n",
      "Procesando archivo: sconcno2_2023121400.nc\n",
      "Procesando archivo: sconcno2_2023121500.nc\n",
      "Procesando archivo: sconcno2_2023121600.nc\n",
      "Procesando archivo: sconcno2_2023121700.nc\n",
      "Procesando archivo: sconcno2_2023121800.nc\n",
      "Procesando archivo: sconcno2_2023121900.nc\n",
      "Procesando archivo: sconcno2_2023122000.nc\n",
      "Procesando archivo: sconcno2_2023122100.nc\n",
      "Procesando archivo: sconcno2_2023122200.nc\n",
      "Procesando archivo: sconcno2_2023122300.nc\n",
      "Procesando archivo: sconcno2_2023122400.nc\n",
      "Procesando archivo: sconcno2_2023122500.nc\n",
      "Procesando archivo: sconcno2_2023122600.nc\n",
      "Procesando archivo: sconcno2_2023122700.nc\n",
      "Procesando archivo: sconcno2_2023122800.nc\n",
      "Procesando archivo: sconcno2_2023122900.nc\n",
      "Procesando archivo: sconcno2_2023123000.nc\n",
      "Procesando archivo: sconcno2_2023123100.nc\n"
     ]
    }
   ],
   "source": [
    "directorio = r'C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/'\n",
    "\n",
    "# Listar los archivos .nc de la carpeta\n",
    "archivos = [archivo for archivo in os.listdir(directorio) if archivo.endswith('.nc')]\n",
    "\n",
    "# Lista para almacenar todos los DataFrames generados\n",
    "lista_dataframes = []\n",
    "def files_añadir(nc_data):\n",
    "    # Seleccionar 1000 filas aleatorias\n",
    "    directorio = r'C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/'\n",
    "\n",
    "    # Listar los archivos .nc de la carpeta\n",
    "    archivos = [archivo for archivo in os.listdir(directorio) if archivo.endswith('.nc')]\n",
    "\n",
    "    # Lista para almacenar todos los DataFrames generados\n",
    "    lista_dataframes = []\n",
    "    def files_añadir(nc_data):\n",
    "        # Seleccionar 1000 filas aleatorias\n",
    "        filas_con_valor_mayor_1 = nc_data.loc[(nc_data['sconcno2'] > 1) & (nc_data['sconcno2'] < 100)]\n",
    "        global NO2\n",
    "        NO2 = pd.concat([NO2, filas_con_valor_mayor_1], axis=0)\n",
    "\n",
    "    # Recorre todos los archivos .nc de la carpeta\n",
    "    for archivo in archivos:\n",
    "        ruta_archivo = os.path.join(directorio, archivo)\n",
    "        print(f\"Procesando archivo: {archivo}\")\n",
    "        \n",
    "        # Abrir el archivo NetCDF\n",
    "        nc_data = xr.open_dataset(ruta_archivo)\n",
    "        nc_data = nc_data.to_dataframe().reset_index()\n",
    "        nc_data['time'] = pd.to_datetime(nc_data['time'])\n",
    "        nc_data = nc_data.drop(columns=['y', 'x', 'lev'])\n",
    "        \n",
    "        sampled_data = files_añadir(nc_data)\n",
    "    global NO2\n",
    "    \n",
    "\n",
    "# Recorre todos los archivos .nc de la carpeta\n",
    "for archivo in archivos:\n",
    "    ruta_archivo = os.path.join(directorio, archivo)\n",
    "    print(f\"Procesando archivo: {archivo}\")\n",
    "    \n",
    "    # Abrir el archivo NetCDF\n",
    "    nc_data = xr.open_dataset(ruta_archivo)\n",
    "    nc_data = nc_data.to_dataframe().reset_index()\n",
    "    nc_data['time'] = pd.to_datetime(nc_data['time'])\n",
    "    nc_data = nc_data.drop(columns=['y', 'x', 'lev'])\n",
    "    \n",
    "    sampled_data = files_añadir(nc_data)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time                 datetime64[ns]\n",
      "lat                         float64\n",
      "lon                         float64\n",
      "sconcno2                    float64\n",
      "Lambert_conformal           float64\n",
      "dtype: object\n",
      "                                time           lat           lon  \\\n",
      "count                        1408972  1.408972e+06  1.408972e+06   \n",
      "mean   2023-08-09 19:46:21.411696128  4.163907e+01  1.724602e+00   \n",
      "min              2023-01-01 00:00:00  4.023144e+01 -1.190186e-03   \n",
      "25%              2023-08-20 23:00:00  4.096356e+01  8.944397e-01   \n",
      "50%              2023-08-21 15:00:00  4.164559e+01  1.721710e+00   \n",
      "75%              2023-08-21 21:00:00  4.231059e+01  2.555359e+00   \n",
      "max              2024-01-01 23:00:00  4.303321e+01  3.521942e+00   \n",
      "std                              NaN  7.755333e-01  9.627296e-01   \n",
      "\n",
      "           sconcno2  Lambert_conformal  \n",
      "count  1.408972e+06       1.076972e+06  \n",
      "mean   7.622168e+36      -2.147484e+09  \n",
      "min    8.777442e-06      -2.147484e+09  \n",
      "25%    9.969210e+36      -2.147484e+09  \n",
      "50%    9.969210e+36      -2.147484e+09  \n",
      "75%    9.969210e+36      -2.147484e+09  \n",
      "max    9.969210e+36      -2.147484e+09  \n",
      "std    4.229605e+36       0.000000e+00  \n",
      "time\n",
      "2023-08-20 23:00:00    82895\n",
      "2023-08-20 21:00:00    82885\n",
      "2023-08-21 15:00:00    82873\n",
      "2023-08-21 18:00:00    82873\n",
      "2023-08-21 12:00:00    82870\n",
      "                       ...  \n",
      "2023-09-30 14:00:00       11\n",
      "2023-07-17 14:00:00       11\n",
      "2023-08-01 14:00:00       11\n",
      "2023-03-24 14:00:00       11\n",
      "2023-03-17 14:00:00       11\n",
      "Name: count, Length: 8544, dtype: int64\n",
      "lat\n",
      "41.284397    664\n",
      "42.859695    664\n",
      "41.045160    664\n",
      "42.876064    664\n",
      "42.509304    664\n",
      "            ... \n",
      "40.701424     13\n",
      "42.903637     13\n",
      "42.904282     13\n",
      "42.904922     13\n",
      "42.905563     13\n",
      "Name: count, Length: 72294, dtype: int64\n",
      "lon\n",
      "2.455536    664\n",
      "3.296356    664\n",
      "0.363892    664\n",
      "1.047058    664\n",
      "1.563446    664\n",
      "           ... \n",
      "3.460693     13\n",
      "3.448456     13\n",
      "3.436218     13\n",
      "3.423950     13\n",
      "3.411713     13\n",
      "Name: count, Length: 65187, dtype: int64\n",
      "sconcno2\n",
      "9.969210e+36    1076972\n",
      "9.969210e+36        287\n",
      "7.967388e-04          3\n",
      "7.922540e-04          3\n",
      "3.276085e-04          3\n",
      "                 ...   \n",
      "9.846125e-04          1\n",
      "6.639797e-04          1\n",
      "1.614824e-03          1\n",
      "6.167061e-04          1\n",
      "1.804899e-03          1\n",
      "Name: count, Length: 330350, dtype: int64\n",
      "Lambert_conformal\n",
      "-2.147484e+09    1076972\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(NO2.dtypes)\n",
    "\n",
    "print(NO2.describe())\n",
    "\n",
    "for i in NO2.columns:\n",
    "    print(NO2[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando archivo: sconcno2_2023010100.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023010100.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023012700.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023012700.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023021900.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023021900.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023031900.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023031900.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023041200.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023041200.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023050600.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023050600.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023053000.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023053000.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023062400.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023062400.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023072000.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023072000.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023081700.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023081700.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023091200.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023091200.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023100600.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023100600.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023110100.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023110100.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023112800.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023112800.nc | Filas extraídas: 165688\n",
      "Procesando archivo: sconcno2_2023122200.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jiahu\\AppData\\Local\\Temp\\ipykernel_4140\\1289764378.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo procesado correctamente: sconcno2_2023122200.nc | Filas extraídas: 165688\n",
      "Archivo CSV guardado en: C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/NO2_final.csv\n",
      "Vista previa de los primeros registros:\n",
      "                 time        lat       lon  sconcno2\n",
      "0 2023-01-01 08:00:00  40.361107 -0.001190  0.632858\n",
      "1 2023-01-01 08:00:00  40.360806  0.010620  0.653797\n",
      "2 2023-01-01 08:00:00  40.360512  0.022430  0.711899\n",
      "3 2023-01-01 08:00:00  40.360210  0.034241  0.701332\n",
      "4 2023-01-01 08:00:00  40.359894  0.046051  0.641413\n",
      "Total de filas: 2485320\n",
      "Columnas del DataFrame: Index(['time', 'lat', 'lon', 'sconcno2'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import random\n",
    "def extract_random_rows_v3(nc_data, num_rows=1000):\n",
    "    \"\"\" Extraer 1000 filas aleatorias de las columnas time, lat, lon y sconcno2. \"\"\"\n",
    "    # Convertir el dataset de xarray a DataFrame y seleccionar solo las columnas necesarias\n",
    "    df = nc_data[['time', 'lat', 'lon', 'sconcno2']].to_dataframe().reset_index()\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    filas_horas_8 = df.loc[df['time'].dt.time == pd.to_datetime('8:00:00').time()]\n",
    "    filas_horas_8['sconcno2'] = filas_horas_8['sconcno2'] * 1912.5\n",
    "    # Seleccionar 1000 filas aleatorias\n",
    "    return filas_horas_8\n",
    "\n",
    "\n",
    "# Ruta de la carpeta donde se encuentran los archivos .nc\n",
    "directorio = r'C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/'\n",
    "\n",
    "# Listar los archivos .nc de la carpeta\n",
    "archivos = [archivo for archivo in os.listdir(directorio) if archivo.endswith('.nc')]\n",
    "\n",
    "# Lista para almacenar todos los DataFrames generados\n",
    "lista_dataframes = []\n",
    "\n",
    "pas=random.randint(20, 30)\n",
    "# Recorre todos los archivos .nc de la carpeta\n",
    "for i in range(0, len(archivos), pas):\n",
    "    archivo = archivos[i]\n",
    "    try:\n",
    "        ruta_archivo = os.path.join(directorio, archivo)\n",
    "        print(f\"Procesando archivo: {archivo}\")\n",
    "        \n",
    "        # Abrir el archivo NetCDF\n",
    "        nc_data = xr.open_dataset(ruta_archivo)\n",
    "        \n",
    "        # Extraer 1000 filas aleatorias\n",
    "        sampled_data = extract_random_rows_v3(nc_data)\n",
    "        \n",
    "        # Agregar el DataFrame a la lista\n",
    "        lista_dataframes.append(sampled_data)\n",
    "        \n",
    "        # Cerrar el dataset para liberar memoria\n",
    "        nc_data.close()\n",
    "        \n",
    "        print(f\"Archivo procesado correctamente: {archivo} | Filas extraídas: {sampled_data.shape[0]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al procesar {archivo}: {e}\")\n",
    "\n",
    "# Concatenar todos los DataFrames\n",
    "data_final = pd.concat(lista_dataframes, ignore_index=True)\n",
    "data_final = data_final.drop(columns=['x', 'y', 'lev'])\n",
    "# Guardar el DataFrame final como CSV\n",
    "output_path = 'C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/NO2_final.csv'\n",
    "data_final.to_csv(output_path, index=False)\n",
    "print(f\"Archivo CSV guardado en: {output_path}\")\n",
    "\n",
    "# Mostrar las primeras filas para verificar\n",
    "print(\"Vista previa de los primeros registros:\")\n",
    "print(data_final.head())\n",
    "\n",
    "# Mostrar información general del DataFrame\n",
    "print(f\"Total de filas: {data_final.shape[0]}\")\n",
    "print(f\"Columnas del DataFrame: {data_final.columns}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time        datetime64[ns]\n",
      "lat                float64\n",
      "lon                float64\n",
      "sconcno2           float64\n",
      "dtype: object\n",
      "                                time           lat           lon      sconcno2\n",
      "count                        2485320  2.485320e+06  2.485320e+06  2.485320e+06\n",
      "mean   2023-06-27 13:35:59.999999744  4.163910e+01  1.726889e+00  3.250757e+00\n",
      "min              2023-01-01 08:00:00  4.023144e+01 -1.190186e-03  1.656196e-02\n",
      "25%              2023-03-20 08:00:00  4.096942e+01  8.902740e-01  7.058631e-01\n",
      "50%              2023-06-24 20:00:00  4.163914e+01  1.726807e+00  1.500392e+00\n",
      "75%              2023-10-06 08:00:00  4.230889e+01  2.562340e+00  3.354762e+00\n",
      "max              2023-12-23 08:00:00  4.303321e+01  3.521942e+00  1.420376e+02\n",
      "std                              NaN  7.742891e-01  9.671841e-01  5.716578e+00\n",
      "time\n",
      "2023-01-01 08:00:00    82844\n",
      "2023-01-02 08:00:00    82844\n",
      "2023-01-27 08:00:00    82844\n",
      "2023-01-28 08:00:00    82844\n",
      "2023-02-19 08:00:00    82844\n",
      "2023-02-20 08:00:00    82844\n",
      "2023-03-19 08:00:00    82844\n",
      "2023-03-20 08:00:00    82844\n",
      "2023-04-12 08:00:00    82844\n",
      "2023-04-13 08:00:00    82844\n",
      "2023-05-06 08:00:00    82844\n",
      "2023-05-07 08:00:00    82844\n",
      "2023-05-30 08:00:00    82844\n",
      "2023-05-31 08:00:00    82844\n",
      "2023-06-24 08:00:00    82844\n",
      "2023-06-25 08:00:00    82844\n",
      "2023-07-20 08:00:00    82844\n",
      "2023-07-21 08:00:00    82844\n",
      "2023-08-17 08:00:00    82844\n",
      "2023-08-18 08:00:00    82844\n",
      "2023-09-12 08:00:00    82844\n",
      "2023-09-13 08:00:00    82844\n",
      "2023-10-06 08:00:00    82844\n",
      "2023-10-07 08:00:00    82844\n",
      "2023-11-01 08:00:00    82844\n",
      "2023-11-02 08:00:00    82844\n",
      "2023-11-28 08:00:00    82844\n",
      "2023-11-29 08:00:00    82844\n",
      "2023-12-22 08:00:00    82844\n",
      "2023-12-23 08:00:00    82844\n",
      "Name: count, dtype: int64\n",
      "lat\n",
      "41.399452    150\n",
      "41.219520    150\n",
      "41.067640    150\n",
      "41.076630    150\n",
      "41.301456    150\n",
      "            ... \n",
      "42.913837     30\n",
      "42.912580     30\n",
      "42.911945     30\n",
      "42.911316     30\n",
      "42.662617     30\n",
      "Name: count, Length: 71304, dtype: int64\n",
      "lon\n",
      "2.931366    600\n",
      "2.930572    570\n",
      "2.560638    570\n",
      "2.234772    540\n",
      "2.234070    510\n",
      "           ... \n",
      "3.044128     30\n",
      "3.080902     30\n",
      "3.117676     30\n",
      "3.129913     30\n",
      "3.142181     30\n",
      "Name: count, Length: 64202, dtype: int64\n",
      "sconcno2\n",
      "1.119766    5\n",
      "1.433344    5\n",
      "2.240090    4\n",
      "1.095197    4\n",
      "1.084367    4\n",
      "           ..\n",
      "1.359790    1\n",
      "1.354168    1\n",
      "1.331475    1\n",
      "1.310423    1\n",
      "0.711899    1\n",
      "Name: count, Length: 2408179, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "NO2_12 = pd.read_csv('C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/CALIOPE/NO2/NO2_final.csv')\n",
    "NO2_12['time'] = pd.to_datetime(NO2_12['time'])\n",
    "print(NO2_12.dtypes)\n",
    "\n",
    "print(NO2_12.describe())\n",
    "for i in NO2_12.columns:\n",
    "    print(NO2_12[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   inspireid   sourceid beginlifes endlifespa  validfrom validto fictitious  \\\n",
      "0   54769333  198794320 2015-10-21        NaT 2015-10-21     NaT          0   \n",
      "1   54800801  198935562 2015-10-21        NaT 2015-10-21     NaT          0   \n",
      "2   54802891  198944072 2015-10-21        NaT 2015-10-21     NaT          0   \n",
      "3   54808949  198965364 2015-10-21        NaT 2015-10-21     NaT          0   \n",
      "4   54808951  198965365 2015-10-21        NaT 2015-10-21     NaT          0   \n",
      "\n",
      "        direction  fromroadno  toroadnode  ... speedlimit capacity maximuheig  \\\n",
      "0  bothDirections    33620027    39891066  ...          0     2000        0.0   \n",
      "1  bothDirections    36092175    39916521  ...         50     4000        0.0   \n",
      "2     inDirection    39918239    39918240  ...          0     3000        0.0   \n",
      "3  bothDirections    39923308    39923309  ...          0     2000        0.0   \n",
      "4  bothDirections    39923311    39923312  ...          0     2000        0.0   \n",
      "\n",
      "  maximumtot maximumwid  vehicletyp  z_order  length_m  trafficvol  \\\n",
      "0        0.0        0.0        None        0       0.0         0.0   \n",
      "1        0.0        0.0        None        0       0.0         0.0   \n",
      "2        0.0        0.0        None        0       0.0         0.0   \n",
      "3        0.0        0.0        None        0       0.0         0.0   \n",
      "4        0.0        0.0        None        0       0.0         0.0   \n",
      "\n",
      "                                            geometry  \n",
      "0    LINESTRING (1.99488 41.66973, 1.99502 41.66971)  \n",
      "1    LINESTRING (2.23387 41.94304, 2.23386 41.94206)  \n",
      "2  LINESTRING (1.68342 41.33341, 1.68351 41.33332...  \n",
      "3    LINESTRING (2.01923 41.57089, 2.01926 41.57088)  \n",
      "4    LINESTRING (2.01857 41.57034, 2.01852 41.57033)  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Ruta al archivo .shp (Geopandas también lee el .dbf)\n",
    "ruta_archivo_shp = 'C:/Users/jiahu/OneDrive/Escritorio/AI3/Bitsxm/Dades/OpenTransportMap/Barcelona/roadlinks_ES511.shp'\n",
    "\n",
    "# Cargar los datos del Shapefile (se incluye automáticamente el archivo .dbf)\n",
    "gdf = gpd.read_file(ruta_archivo_shp)\n",
    "\n",
    "# Convertir a DataFrame de Pandas\n",
    "#df = gdf.drop(columns='geometry')  # Eliminar la columna de geometría si no la necesitas\n",
    "\n",
    "# Mostrar las primeras filas\n",
    "print(gdf.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
