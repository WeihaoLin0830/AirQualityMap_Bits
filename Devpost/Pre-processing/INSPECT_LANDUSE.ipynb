{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo MUCSC_2022_10_m_v_3.hdr...\n",
      "Leyendo MUCSC_2022_10_m_v_3.sld...\n",
      "Leyendo MUCSC_2022_10_m_v_3.TFW...\n",
      "Leyendo MUCSC_2022_10_m_v_3.xml...\n",
      "Leyendo MUCSC_2022_10_m_v_3_tiff_atributs_0_0.dbf...\n",
      "Leyendo MUCSC_2022_30_m_v_3.hdr...\n",
      "Leyendo MUCSC_2022_30_m_v_3.sld...\n",
      "Leyendo MUCSC_2022_30_m_v_3.TFW...\n",
      "Leyendo MUCSC_2022_30_m_v_3.xml...\n",
      "Leyendo MUCSC_2022_30_m_v_3_tiff_atributs_0_0.dbf...\n",
      "\n",
      "DataFrames del grupo grupo_1:\n",
      "- MUCSC_2022_10_m_v_3.hdr: 10 filas, 2 columnas\n",
      "- MUCSC_2022_10_m_v_3.sld: 45 filas, 2 columnas\n",
      "- MUCSC_2022_10_m_v_3.TFW: 6 filas, 2 columnas\n",
      "- MUCSC_2022_10_m_v_3.xml: 492 filas, 3 columnas\n",
      "- MUCSC_2022_10_m_v_3_tiff_atributs_0_0.dbf: 25 filas, 2 columnas\n",
      "\n",
      "DataFrames del grupo grupo_2:\n",
      "- MUCSC_2022_30_m_v_3.hdr: 10 filas, 2 columnas\n",
      "- MUCSC_2022_30_m_v_3.sld: 45 filas, 2 columnas\n",
      "- MUCSC_2022_30_m_v_3.TFW: 6 filas, 2 columnas\n",
      "- MUCSC_2022_30_m_v_3.xml: 492 filas, 3 columnas\n",
      "- MUCSC_2022_30_m_v_3_tiff_atributs_0_0.dbf: 25 filas, 2 columnas\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "\n",
    "def read_hdr_file(file_path):\n",
    "    \"\"\"Lee el archivo .hdr y lo convierte a un DataFrame.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.readlines()\n",
    "        data = {'Line': list(range(1, len(content) + 1)), 'Content': [line.strip() for line in content]}\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def read_sld_file(file_path):\n",
    "    \"\"\"Lee el archivo .sld y lo convierte a un DataFrame.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.readlines()\n",
    "        data = {'Line': list(range(1, len(content) + 1)), 'Content': [line.strip() for line in content]}\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def read_tfw_file(file_path):\n",
    "    \"\"\"Lee el archivo .tfw y lo convierte a un DataFrame.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            content = file.readlines()\n",
    "        data = {'Line': list(range(1, len(content) + 1)), 'Content': [line.strip() for line in content]}\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def read_xml_file(file_path):\n",
    "    \"\"\"Parsea el archivo XML y convierte los elementos a un DataFrame.\"\"\"\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        root = tree.getroot()\n",
    "        elements = []\n",
    "        for element in root.iter():\n",
    "            tag = element.tag\n",
    "            text = element.text.strip() if element.text else None\n",
    "            attributes = element.attrib\n",
    "            elements.append({'Tag': tag, 'Text': text, 'Attributes': attributes})\n",
    "        \n",
    "        df = pd.DataFrame(elements)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def read_dbf_file(file_path):\n",
    "    \"\"\"Lee un archivo .dbf y lo convierte a un DataFrame de pandas.\"\"\"\n",
    "    try:\n",
    "        from dbfread import DBF\n",
    "        table = DBF(file_path, encoding='latin1')\n",
    "        df = pd.DataFrame(iter(table))\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error leyendo {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Función principal para leer los archivos y convertirlos a DataFrames de pandas.\"\"\"\n",
    "    file_groups = {\n",
    "        'grupo_1': {\n",
    "            'MUCSC_2022_10_m_v_3.hdr': read_hdr_file,\n",
    "            'MUCSC_2022_10_m_v_3.sld': read_sld_file,\n",
    "            'MUCSC_2022_10_m_v_3.TFW': read_tfw_file,\n",
    "            'MUCSC_2022_10_m_v_3.xml': read_xml_file,\n",
    "            'MUCSC_2022_10_m_v_3_tiff_atributs_0_0.dbf': read_dbf_file\n",
    "        },\n",
    "        'grupo_2': {\n",
    "            'MUCSC_2022_30_m_v_3.hdr': read_hdr_file,\n",
    "            'MUCSC_2022_30_m_v_3.sld': read_sld_file,\n",
    "            'MUCSC_2022_30_m_v_3.TFW': read_tfw_file,\n",
    "            'MUCSC_2022_30_m_v_3.xml': read_xml_file,\n",
    "            'MUCSC_2022_30_m_v_3_tiff_atributs_0_0.dbf': read_dbf_file\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    base_path = \"C:\\\\Users\\\\jiahu\\\\OneDrive\\\\Escritorio\\\\AI3\\\\Bitsxm\\\\Dades\\\\LandUse\\\\\"\n",
    "    all_dataframes = {}\n",
    "\n",
    "    for group_name, files in file_groups.items():\n",
    "        group_dfs = {}\n",
    "        for file_name, read_function in files.items():\n",
    "            file_path = os.path.join(base_path, file_name)\n",
    "            if os.path.exists(file_path):\n",
    "                print(f\"Leyendo {file_name}...\")\n",
    "                df = read_function(file_path)\n",
    "                group_dfs[file_name] = df\n",
    "            else:\n",
    "                print(f\"El archivo {file_name} no se encontró en {base_path}.\")\n",
    "        \n",
    "        all_dataframes[group_name] = group_dfs\n",
    "\n",
    "    return all_dataframes\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    all_dataframes = main()\n",
    "    \n",
    "    # Verificar la estructura de los DataFrames\n",
    "    for group_name, dfs in all_dataframes.items():\n",
    "        print(f\"\\nDataFrames del grupo {group_name}:\")\n",
    "        for file_name, df in dfs.items():\n",
    "            print(f\"- {file_name}: {df.shape[0]} filas, {df.shape[1]} columnas\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
